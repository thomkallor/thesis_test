{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cifar-10-batches-bin/\n",
       "cifar-10-batches-bin/data_batch_1.bin\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "cifar-10-batches-bin/batches.meta.txt\n",
       "cifar-10-batches-bin/data_batch_3.bin\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "cifar-10-batches-bin/data_batch_4.bin\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "cifar-10-batches-bin/test_batch.bin\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "cifar-10-batches-bin/readme.html\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "cifar-10-batches-bin/data_batch_5.bin\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "cifar-10-batches-bin/data_batch_2.bin\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : ByteTensor - size: 50000x3x32x32\n",
       "  label : ByteTensor - size: 50000\n",
       "}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "  data : ByteTensor - size: 10000x3x32x32\n",
       "  label : ByteTensor - size: 10000\n",
       "}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'torch'\n",
    "\n",
    "os.execute('wget -c http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz')\n",
    "os.execute('tar -xvf cifar-10-binary.tar.gz')\n",
    "local function convertCifar10BinToTorchTensor(inputFnames, outputFname)\n",
    "   local nSamples = 0\n",
    "   for i=1,#inputFnames do\n",
    "      local inputFname = inputFnames[i]\n",
    "      local m=torch.DiskFile(inputFname, 'r'):binary()\n",
    "      m:seekEnd()\n",
    "      local length = m:position() - 1\n",
    "      local nSamplesF = length / 3073 -- 1 label byte, 3072 pixel bytes\n",
    "      assert(nSamplesF == math.floor(nSamplesF), 'expecting numSamples to be an exact integer')\n",
    "      nSamples = nSamples + nSamplesF\n",
    "      m:close()\n",
    "   end\n",
    "\n",
    "   local label = torch.ByteTensor(nSamples)\n",
    "   local data = torch.ByteTensor(nSamples, 3, 32, 32)\n",
    "\n",
    "   local index = 1\n",
    "   for i=1,#inputFnames do\n",
    "      local inputFname = inputFnames[i]\n",
    "      local m=torch.DiskFile(inputFname, 'r'):binary()\n",
    "      m:seekEnd()\n",
    "      local length = m:position() - 1\n",
    "      local nSamplesF = length / 3073 -- 1 label byte, 3072 pixel bytes\n",
    "      m:seek(1)\n",
    "      for j=1,nSamplesF do\n",
    "         label[index] = m:readByte()\n",
    "         local store = m:readByte(3072)\n",
    "         data[index]:copy(torch.ByteTensor(store))\n",
    "         index = index + 1\n",
    "      end\n",
    "      m:close()\n",
    "   end\n",
    "\n",
    "   local out = {}\n",
    "   out.data = data\n",
    "   out.label = label\n",
    "   print(out)\n",
    "   torch.save(outputFname, out)\n",
    "end\n",
    "\n",
    "convertCifar10BinToTorchTensor({'cifar-10-batches-bin/data_batch_1.bin',\n",
    "                                'cifar-10-batches-bin/data_batch_2.bin',\n",
    "                                'cifar-10-batches-bin/data_batch_3.bin',\n",
    "                                'cifar-10-batches-bin/data_batch_4.bin',\n",
    "                                'cifar-10-batches-bin/data_batch_5.bin'},\n",
    "   'cifar10-train.t7')\n",
    "\n",
    "convertCifar10BinToTorchTensor({'cifar-10-batches-bin/test_batch.bin'},\n",
    "   'cifar10-test.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "require 'paths'\n",
    "trainset = torch.load('cifar10-train.t7')\n",
    "testset = torch.load('cifar10-test.t7')\n",
    "classes = {'airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.label = trainset.label+1\n",
    "testset.label = testset.label+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "-- ignore setmetatable for now, it is a feature beyond the scope of this tutorial. It sets the index operator.\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end\n",
    "\n",
    "-- ignore setmetatable for now, it is a feature beyond the scope of this tutorial. It sets the index operator.\n",
    "setmetatable(testset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "testset.data = testset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function testset:size() \n",
    "    return self.data:size(1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = trainset.data[{ {}, {1}, {}, {}  }]*0.21\n",
    "g = trainset.data[{ {}, {2}, {}, {}  }]*0.72\n",
    "b = trainset.data[{ {}, {3}, {}, {}  }]*0.07\n",
    "trainset.data = r+g+b\n",
    "r = testset.data[{ {}, {1}, {}, {}  }]*0.21\n",
    "g = testset.data[{ {}, {2}, {}, {}  }]*0.72\n",
    "b = testset.data[{ {}, {3}, {}, {}  }]*0.07\n",
    "testset.data = r+g+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "automobile\t\n",
       "2\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADSklEQVQ4jQXBTW/cRBgA4PedGY/Ha++H42zSpNl8FGjVXioRJD4kpFbiwqESP4Iz/D2OwIFLpUqlokRqwwHSJrtZZ9e79ozt+Xh5HvymsmIQWCdshLIYv6bH568+xPnuV/rd/m4y/FOAQImgSQqOVWlgUP4ObWKy5GhdjIxOhM9679rMBhAY9wrhJjIQd5cmOaqbaFuKuIJkoKnPvO5iFOClJWoyvdC50i2txLabtG5TFWrTyIaotTwCz4S9i9ewGLlaxGrjeFuMrr2KYt1KCixykah9fuP61rc89yyC08NeoOhHOxHsDS0hyK71WgbLev4gsZFiBKOtdsW4UwNmctRGigB+A8kePyiHxLK+l5A6a2HUtWkUL5SLeg3COsPHjpWdIARMHBK0xFH2G5P23dh0Zqv48abxgZ+Qdm5Q0MZ7q8Q4EyGkE79Ix0EkgtTe1NfG3ss7HdxZhwKj9FbJOh03Y8Wtjw4LZnlc5m5pw0By2LYubJG1lAeGLLTZQz+nCdxL6/7hdxF/V5MzdXw2DKECDfxkLfRKzH0b6nj15bNqebrk3cFtuudZJW2W8Ef9XVBd3NfNHM3R8iQ9/618fKYbwsYfMpbxfW46OV4N6qVe1D/BtvRf0Gxf+lsLpiqjT3i/HhwHB7eD0WS49/MMX//73Lx6zruklAOVZAyLKCZz7CUyG9yz7/97efN0zdjqRB5g3M/n7/lBsd1U06/Pp6vK0fvZh7MXx5/9Mj6QO59+/u2gWq5FvGmz4/v1xceOWc9+jbRZueYi0eiKk8RsFL7IcUGzwzfXGAYxG07iSGV5ophjYy7g5R/4YxT+2n0w/zh7tD+S/WptVdBBgO1YqoZ7XS+yaB2W83x2Orx9W3cmOB85J8lxAIvKkOj6a7TU1H+HEJAhJwKCAESAEJZ3ThTbsiVou8J6AgeWkBAAAAjZRj9NhHprCKjMpvcuLwoAQGAEAAAIrrr/Q8rMnQRoaAqjXDYMEQEQEABgR8L08oolx1NAE8WTEscdEREQAQEA2F5mzVzInavNVhfD/WA6mx8RBAIgBIdmLvzUi0zZStNWPbn7p62uasYZciREAL9lLlbiiOuZ8ddvnqSLFV8ujEUCAEAUoxpKPP0f9WDpexZLWCMAAAAASUVORK5CYII=",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADNUlEQVQ4jTXMW29UVRQA4LXW3vucM3POmUsLRTplWiiWEBCDMYIh6oP+A9/9Sf4IExPjgzFiePWFeA9vkjYqhZZaaacd5nIu+7aWT34/4MNjTQBgoA1IgAoBABBAABEJibSLCGhOuUgQJJCKjAggACAoCKAJgeivz7c+Wxekk59H9xMAQokAqFAjaUOgzHeP1h5saJb8yffZhwggIgAASEikTGrwgF48t8qY/X+fPK4ARAARAYSFdZYoDAPN55JWL7/5yc7aAgAEGIAABLUxAOrTH6Y/brRPJ7OL2U7HIYj83ygdhHQcrqwefUk2lNtv3zceCQAEQFiAdJO4vV+O8Fo3u1gaLfPfyjFGYBEABEDCef3wq8mo7hszVBHZmq33bg+dMDAQkSF89vW3f9/SOEwhSpag0rEZfXIjMoAwaWS18cXTzZE6oMM/DluV6DTP4xHccD5ysM62Xj96WV7P/pnnSSp+bkLjep077/cZEFmEifReuJt4X5yOr3vopgS1dHVqGAFEABQqN7pqQyibZbaap1mWpyLerpQxeB98jEEldzqzCDqtFtzVgXUnac/2d5u1jAUQhNT2GiyE2WRuWTOKmx4eHE+e/V6NxdrWSVC3ICywYd3NbK1Ku/88rPbzC6WNeHp2Mq0OdYISQ50QJR2YL5zvr5XUQ+nO1WVhjLtqjGhzXzO71xU35o0eGTo/g7NXx6k9mTddHTRrQ/OZwrQrrkoTVzW/dtaN2lvcnRVZpnYgCk0q29oHH7UTVwUWiF10aW/szPn5RL3Jnn0rCKo+Km5vDwEpCCtQ1+41hQuV9pGBkxBD7923ttrj/sqLx7ttMFn/5uVVWqdW6wA21lXAjY8vLfKNrNhpjl9TsfnBPZeoKKWufM0+kA5XUjTOGU7e2TxzF0Zl1JpiutTIrDEwZf1lz7r5bNzrDG4q61KfJC3lrYaIEoBwnf+0SWpe4aU0jQ5k2qlWFHBfNz4iKpWOigxL09EI1icsbl5mi0FYMjEoYWUGvW6epyZZKfSwUAPt1VR7W05r4hgikVlXM4mSYODooq3SQg2irmrldFAEoLpX+kvx81pYhYViQhOWRtgNpv8BcOjGzTrsemkAAAAASUVORK5CYII=",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "horse\t\n",
       "8\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itorch.image(trainset.data[100]) -- display the 100-th image in dataset\n",
    "print(classes[trainset.label[100]])\n",
    "print(trainset.label[100])\n",
    "itorch.image(testset.data[100]) -- display the 100-th image in dataset\n",
    "print(classes[testset.label[100]])\n",
    "print(testset.label[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel 1, Mean: 122.80931339391\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 1, Standard Deviation: 61.229392750446\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv  = {} -- store the standard-deviation for the future\n",
    "for i=1,1 do -- over each image channel\n",
    "    mean[i] = trainset.data[{ {}, {i}, {}, {}  }]:mean() -- mean estimation\n",
    "    print('Channel ' .. i .. ', Mean: ' .. mean[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction\n",
    "    \n",
    "    stdv[i] = trainset.data[{ {}, {i}, {}, {}  }]:std() -- std estimation\n",
    "    print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end\n",
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv  = {} -- store the standard-deviation for the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(1, 6, 5, 5)) -- 3 input image channels, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.ReLU())                       -- non-linearity \n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'cunn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net:cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = criterion:cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.data = trainset.data:cuda()\n",
    "trainset.label = trainset.label:cuda()\n",
    "testset.data = testset.data:cuda()\n",
    "testset.label = testset.label:cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 10 -- just do 5 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.9166581060696\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.5316637751555\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.3497945787978\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.2188308301401\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.1261821846294\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.0545580923319\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.99495678667545\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.94322364642382\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.89797569434166\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.85599119363546\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 0.85599119363546\t\n",
       "287\t\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstart=os.time()\n",
    "trainer:train(trainset)\n",
    "tend=os.time()\n",
    "print(os.difftime (tend , tstart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2820\t28.2 % \t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end\n",
    "print(correct, 100*correct/10000 .. ' % ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airplane\t83.1 %\t\n",
       "automobile\t21.3 %\t\n",
       "bird\t1.8 %\t\n",
       "cat\t26.2 %\t\n",
       "deer\t0 %\t\n",
       "dog\t71.6 %\t\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "frog\t0.5 %\t\n",
       "horse\t13.7 %\t\n",
       "ship\t31.9 %\t\n",
       "truck\t31.9 %\t\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_performance = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n",
    "for i=1,10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end\n",
    "for i=1,#classes do\n",
    "    print(classes[i], 100*class_performance[i]/1000 .. ' %')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
